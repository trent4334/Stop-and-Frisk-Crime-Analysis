---

## ğŸ“ Part A â€“ Predictive Modeling of NYC Stop-and-Frisk (2008â€“2016)

### ğŸ¯ Objective
Build and evaluate logistic regression models to predict if a weapon was found during a stop. Focus is placed on **temporal generalization** and AUC (Area Under Curve) analysis.

### ğŸ”¨ Data Processing Pipeline (`Stop and Frisk-A.R`)

#### `clean_sqf()`
- Filters to `suspected.crime == "cpw"` (criminal possession of a weapon)
- Removes Precinct 121 and incomplete rows
- Selects critical columns:
  - Stop circumstances (e.g., `additional.*`, `stopped.bc.*`)
  - Subject demographics (age, build, sex, height, weight)
  - Location/time indicators
- Converts `time.period` and `precinct` to factors

#### `split_sqf_data()`
- Restricts to data from 2013â€“2015
- Splits into:
  - `sqf_pre_train`: training set (2013â€“2014)
  - `sqf_pre_test`: testing set (2013â€“2014)
  - `sqf_2015`: held-out set for forward validation
- Ensures no leakage by **not using random shuffling across years**

---

### ğŸ¤– Logistic Regression Models

#### `logistic_model_1()`
- Trained on `sqf_pre_train`  
- Predicts weapon possession using all variables  
- Evaluated using **AUC** on:
  - `sqf_pre_test` (in-time validation)
  - `sqf_2015` (forward generalization)

ğŸ“Š **AUC Results**

![AUC Table](./screenshots/auc_summary_table.png)

#### Insight:
AUC was significantly lower on the 2015 data, indicating that even a robust model may generalize poorly across years due to changes in policy, community behavior, or data collection.

---

#### `logistic_model_2()`
- Trains model only on 2008 data  
- Applies model to each year (2009â€“2016)  
- Returns a **yearly AUC trend**

ğŸ“Š **AUC by Year Table**

![AUC Table Yearly](./screenshots/auc_yearly_trend.png)

ğŸ“ˆ **Trend Visualization**





ğŸ§  **Interpretation**:
The steady decline in AUC from 2009 to 2016 highlights how the model becomes increasingly outdated as data evolves. This supports the importance of retraining and adapting models over time for law enforcement analytics.

---

## ğŸŒ† Part B â€“ Scraping & Analyzing Boston Crime Data

### ğŸ¯ Objective
Scrape structured crime reports by hour and neighborhood from [Universal Hub](https://www.universalhub.com/crime/home.html) to analyze temporal crime patterns.

### ğŸ•¸ï¸ Web Scraping Workflow (`Stop and Frisk-B.R`)

#### `scrape_data()`
- Loops through 20 Boston neighborhoods
- Extracts:
  - `crime` type
  - `hour` (from timestamps using `lubridate`)
  - `nbhd` (standardized to lowercase with hyphens)
- Cleans known typos and blanks (e.g., `"Stabbin"` â†’ `"Stabbing"`, empty â†’ `NA`)
- Returns a cleaned tibble with all incidents

ğŸ“Š **Sample Output Preview**

![Scraped Table](./screenshots/scraped_data_table.png)

---

### â° Visualizing Temporal Crime Patterns

#### Total Crimes by Hour

![Hourly Crime Plot](./screenshots/hourly_boston_crime.png)

ğŸ“Œ *Insight*: Peak activity occurs around 9 PM, with a clear rise in late evening hours across neighborhoods.

#### Top 6 Crime Types by Hour (`facet_wrap()` plot)

![Top Crime Types](./screenshots/top6_crime_facet_plot.png)

ğŸ“Œ *Insight*: Most crime types follow a similar temporal profile, emphasizing risk concentration at night.

---

## ğŸ§  Key Learnings

- **Temporal data splitting** is critical for realistic model evaluation in policy and public safety datasets
- **Generalization drops over time**, even for logistic models with good internal validation
- **Web data is messy**: Requires thoughtful cleaning, standardization, and error correction
- **Crime is time-sensitive**: Time-of-day patterns are consistent across crime types and locations

---

## ğŸ’¼ Use Cases & Applications

- **Law enforcement**: Improve resource allocation by time/location-based crime predictions
- **Public policy**: Evaluate stop-and-frisk model reliability over time
- **Web scraping pipeline**: Scalable for any multi-page, semi-structured data source

---

## ğŸ“Œ Next Steps

- Add **Random Forest** and **XGBoost** models for better nonlinear performance
- Explore **geospatial analysis** using `leaflet` or `sf`
- Develop **automated retraining pipeline** to monitor model decay over time
- Visualize **neighborhood-specific trends** in both NYC and Boston

---

## ğŸ‘¤ Author

**Trent Yu**  
Graduate Student â€“ Data Analytics | NYU  
Focus: Public Safety, Predictive Modeling, Web Data  
ğŸ“« [LinkedIn](https://www.linkedin.com/in/your-link) â€¢ [GitHub](https://github.com/your-profile)

---

## ğŸ“ License

This project is for academic and portfolio purposes. No real-time predictions are made or advised based on the content herein.
