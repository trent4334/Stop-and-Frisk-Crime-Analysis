---

## ğŸ“Š Part 1: Predictive Modeling on NYC Stop-and-Frisk Data

Using data from 2008â€“2016, I built a logistic regression model to predict whether a weapon was found during a police stop. The data was filtered to focus on stops involving a suspected criminal possession of a weapon (`cpw`), and cleaned to ensure completeness.

### âœ… Data Preprocessing

- Filtered for `cpw` stops
- Removed stops with missing values
- Selected key features (stop circumstances, subject demographics, etc.)
- Converted time-based features into factors

### ğŸ“ Data Split Strategy

To avoid data leakage in this time-series context:

- Train/test split was **time-based** (not random)
- Training: 2013â€“2014  
- Validation: 2015

### âš™ï¸ Model 1 â€“ Trained on 2013â€“2014

This model was evaluated using AUC on both the 2013â€“2014 test set and the held-out 2015 data.

ğŸ“Š **AUC Scores**

![Table 1: AUC values](./screenshots/Screenshot_2025-06-05_at_16.16.17.png)

ğŸ“ˆ **Insight**: The AUC on the 2015 set was noticeably lower, suggesting that predictive power drops over time due to changing patterns in policing or stop conditions.

---

### ğŸ“‰ Model 2 â€“ Trained on 2008, Tested Year-by-Year

A second model was trained only on 2008 data and tested across 2009â€“2016 to assess generalization over time.

ğŸ“Š **AUC by Year**

![Table 2: AUC by Year](./screenshots/Screenshot_2025-06-05_at_16.16.28.png)

ğŸ“ˆ **AUC Trend**

![Figure: AUC line plot](./screenshots/Screenshot_2025-06-05_at_16.16.39.png)

ğŸ” **Observation**: AUC declines steadily after 2008, reflecting possible structural changes in stop patterns or community dynamics.

---

## ğŸŒ‡ Part 2: Web Scraping and Crime Trend Analysis (Boston)

I scraped reported crime data from [Universal Hub](https://www.universalhub.com/crime/home.html) for 20 neighborhoods in Boston. The dataset includes:

- **Crime type**
- **Time of day (hour)**
- **Neighborhood**

### ğŸ§¹ Cleaning Highlights

- Converted timestamps to hour (0â€“23)
- Standardized neighborhood names (e.g., `back-bay`)
- Fixed typos like `"Stabbin"` â†’ `"Stabbing"` and `"dangeous"` â†’ `"dangerous"`
- Encoded blanks as `NA`

ğŸ“Š **Sample Data Preview**

![Sample scraped table](./screenshots/Screenshot_2025-06-05_at_16.16.17.png)

---

### â° Hourly Crime Patterns

I aggregated all crimes to visualize trends by hour.

ğŸ“ˆ **Total Crimes by Hour**

![Hourly crime pattern](./screenshots/Screenshot_2025-06-05_at_16.16.28.png)

ğŸ§  **Observation**: Crime incidents spike in the late evening, peaking around 9 PM, consistent with low-light, high-activity periods.

---

### ğŸ” Crime Type Breakdown (Top 6)

To explore specific behaviors, I plotted hourly trends for the six most frequent crimes using `facet_wrap`.

ğŸ“ˆ **Hourly Trend by Crime Type**

![Top 6 crime types](./screenshots/Screenshot_2025-06-05_at_16.16.39.png)

ğŸ§  **Takeaway**: Despite some variation, all major crime types show similar peaks in the late evening, reinforcing the importance of time-based policing strategies.

---

## ğŸ¯ Key Learnings

- **Temporal evaluation matters**: For real-world data like policing, random splits can mislead model performance.
- **Data changes over time**: Even strong models degrade with policy or behavioral shifts.
- **Scraping real-world data** teaches resilience: Inconsistent structures, typos, and formatting issues are the norm.
- **Visualization reveals patterns** not obvious from raw tables.

---

## ğŸ§‘â€ğŸ’» Author

**Trent Yu**  
Data Analytics Graduate Student | R | Python | Tableau  
New York, NY  
ğŸ“« [LinkedIn](https://linkedin.com/in/your-profile) â€¢ [GitHub](https://github.com/your-profile)

---

## ğŸ“Œ Next Steps

- Try ensemble models like Random Forest or XGBoost on the stop-and-frisk data
- Expand the crime scraper to include sentiment analysis from article content
- Use time series modeling to predict hourly crime rates in Boston neighborhoods
